# module Parser

# end

# #!/usr/bin/ruby

# require 'rubygems'
# require 'time'
# require 'optparse'
# require 'fileutils'
# require 'pp'
# require 'erb'
# require 'json'

# file = __FILE__

# log = "/var/log/puppet/puppet.log"
# output = :console
# outfile = nil

# $header = ["service", "start time", "end time", "duration (s)"]
# $footer = ["", "", "total duration (s)"]

# class ChartErb
# 	attr_reader :domain, :range, :start_time, :end_time, :host

#  	def initialize domain, data, host, start_time, end_time, template
#         @domain = domain
#         @length = domain.length
#         @range = range domain.length
#         @data = data 
#         @template = template
#         @start_time = start_time
#         @end_time = end_time
#         @host = host
#         # pp self
#     end

#     def range(n)
#     	i =0.0
#     	res = []
#     	n.times { res << i ; i = i + (1.0 / (n-1) * 10000).floor/10000.0 }
#     	res 
#     end

#     def title
#     	"Provisioning #{host}"
#     end

#     def subtitle
#     	"Puppet run started #{start_time.strftime('%Y-%m-%d %H:%M:%S')} duration: #{end_time - start_time}s"
#     end

#     def load
#     	File.read(@template)
#     end

#     def render
#         ERB.new(load).result( binding )
#     end
# end

# def help
# 	<<~EOH
# 	usage: parser.rb [options]

# 	  -f, --file <path>.   : parse the provided puppet 3 provisioning log [default /var/log/puppet/puppet.log]
# 	  -h, --html           : output a rendered html/d3.js visualisation 
# 	  -c, --csv            : output csv
# 	  -o, --outfile <path> : write output to file <path>
	  
# 	  default behaviour renders a tab-separated table to console.
# 	EOH
# end

# # This works around the limits of trying to lay pie slices out in a circular pattern - if small sections are too
# # close together the lables collide, so this helps avoid it by interleving large and small sections to try to maintain
# # a constant radial speed around the pie chart.
# def layout(data)
# 	a = data.sort {|a,b| b[3] <=> a[3] }

# 	res = [a.first]

# 	l = a.length-1

# 	half_partial_sum = a[2..-1].reduce(0) { |i,a| i + a[3] } / 2 # mean of all the samples less the largest two

# 	# take the remainder of the list excluding the two largest entries
# 	remainder = a[2..-1]

# 	# take the lower half of this list

# 	highers = a[2..(remainder.length/2)+1]
# 	lowers  = a[(remainder.length/2 + 2)..-1].reverse

# 	accumulator = 0
# 	i = 0
# 	set = false

# 	while i < [highers.length, lowers.length].max do

# 		if i < lowers.length
# 			res << lowers[i]
# 			accumulator += lowers[i][3]

# 			if accumulator >= half_partial_sum && !set ## append the second largest value if we've reached the half partial sum
# 				res << a[1]
# 				set = true
# 			end
# 		end

# 		if i < highers.length
# 			res << highers[i]
# 			accumulator += highers[i][3]

# 			if accumulator >= half_partial_sum && !set  ## append the second largest value if we've reached the half partial sum
# 				res << a[1]
# 				set = true
# 			end
# 		end

# 		i += 1
# 	end

# 	res
# end

# def writefile(p, content)
# 	FileUtils.mkdir_p(File.dirname(p))
# 	IO.write(p, content)
# end	

# def ptime st
#     Time.parse(st)
# end

# # emission code - csv, tab and rendered erb.

# def emit_tabbed(catalog, t_end, t_start)
# 	emit_text catalog, "%20s\t%20s\t%20s\t%20s", t_end, t_start
# end

# def emit_csv(catalog, t_end, t_start)
# 	emit_text catalog, "%s,%s,%s,%s", t_end, t_start
# end

# def emit_text(catalog, fmt, t_end, t_start) 
# 	res = []
# 	res << fmt % $header
# 	catalog.each { |c| res << fmt % c }
# 	res << fmt % ($footer.dup << ptime(t_end)-t_start)
# end		

# def emit_html(catalog, host, t_end, t_start)
# 	domain = catalog.collect {|e| e[0] } # collect service name as domain of chart
# 	range = JSON.generate(catalog.collect {|e| { label: e[0], value: e[3] }}) # collect service provision duration in seconds as range

# 	[ChartErb.new(domain, range, host, t_start, ptime(t_end), "./page.html.erb").render]
# end

# # parse command line arguments and begin processing

# ARGV.options do |opts|
#   opts.on("-f", "--file=val", String)      { |val| log = val }
#   opts.on("-h", "--html")              	   { output = :html }
#   opts.on("-c", "--csv")			       { output = :csv }
#   opts.on("-o", "--outfile=val", String)   { |val| outfile = val }
#   opts.on_tail("-h", "--help")             { puts help }
#   opts.parse!
# end

# unless File.exist?(log)
# 	puts help
# 	exit 1
# end

# f = open log

# # accumulators
# start = ""
# t_start = ""
# t_end = ""
# host = ""

# catalog = []

# # process the log file looking for key markers
# begin
# 	f.readlines().each do |l|
# 		if m = /Creating a new SSL key for (\w+\.\w+\.\w+)/.match(l)
# 			start = "#{l[0..18]}"
# 			t_start = ptime(start)
# 			host = m.captures.first # hostname
# 		end

# 		if /npe-apt-update-cache.*executed successfully/.match(l)
# 		  start = "#{l[0..18]}"
# 		end

# 		if m = /Unscheduling refresh on Service\[([\w-]+)\]/.match(l)
# 			catalog << [ m.captures.first, start, l[0..18], (ptime(l[0..18]) - ptime(start)) ]

# 			start = l[0..18]
# 		end

# 		if m = /Puppet \(notice\): Applied catalog in/.match(l)
# 			t_end = l[0..18]
# 		end
# 	end
# ensure
# 	f.close
# end

# # determine output format
# result = 
# 	if output == :console
# 		emit_tabbed catalog, t_end, t_start
# 	elsif output == :csv
# 		emit_csv catalog, t_end, t_start
# 	else
# 		emit_html layout(catalog), host, t_end, t_start
# 	end			

# # output to file or console 
# if outfile
# 	puts "Writing output to #{outfile}"
# 	writefile(outfile, result.join("\n"))
# 	puts "Done."
# else
# 	puts "Puppet provisioning run results\n\n"
# 	puts result
# 	puts "\n"
# end

# # end